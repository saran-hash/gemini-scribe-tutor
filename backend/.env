# Backend environment variables
CHROMA_PATH=./chroma_db
CHROMA_COLLECTION=study_chunks
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Use gemma:2b model for Ollama (smaller than 7b, should fit modest RAM)
OLLAMA_MODEL=tinyllama:latest
HOST=127.0.0.1
PORT=5000
UPLOADS_DIR=./uploads
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173,http://localhost:8080,http://127.0.0.1:8080

# Google Generative API (Gemini) configuration
# Set your API key in `LLM_API_KEY` (keep this secret; do NOT commit it to source control)
LLM_API_PROVIDER=google
LLM_API_URL=https://generativelanguage.googleapis.com/v1beta/models/gemini-flash-lite-latest:generateContent

LLM_API_MODEL=gemini-2.5-flash-lite-preview-09-2025
LLM_API_KEY=AIzaSyBfo8NVS6PmnZWquUfE15chqnnynyDcDJw
